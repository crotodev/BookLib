<?xml version='1.0' encoding='utf-8'?>
<package xmlns="http://www.idpf.org/2007/opf" unique-identifier="uuid_id" version="2.0">
    <metadata xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:opf="http://www.idpf.org/2007/opf">
        <dc:identifier opf:scheme="calibre" id="calibre_id">615</dc:identifier>
        <dc:identifier opf:scheme="uuid" id="uuid_id">41b1d7f5-420a-4d28-a56c-53769b9b73ae</dc:identifier>
        <dc:title>Website Scraping With Python: Using BeautifulSoup and Scrapy</dc:title>
        <dc:creator opf:file-as="Hajba, Gábor László" opf:role="aut">Gábor László Hajba</dc:creator>
        <dc:contributor opf:file-as="calibre" opf:role="bkp">calibre (6.14.0) [https://calibre-ebook.com]</dc:contributor>
        <dc:date>2018-09-14T04:00:00+00:00</dc:date>
        <dc:description>&lt;div&gt;
&lt;h3&gt;Product Description&lt;/h3&gt;
&lt;p&gt;Closely examine website scraping and data processing: the technique of extracting data from websites in a format suitable for further analysis. You'll review which tools to use, and compare their features and efficiency. Focusing on BeautifulSoup4 and Scrapy, this concise, focused book highlights common problems and suggests solutions that readers can implement on their own.&lt;br&gt;&lt;em&gt;Website Scraping with Python&lt;/em&gt; starts by introducing and installing the scraping tools and explaining the features of the full application that readers will build throughout the book. You'll see how to use BeautifulSoup4 and Scrapy individually or together to achieve the desired results. Because many sites use JavaScript, you'll also employ Selenium with a browser emulator to render these sites and make them ready for scraping.&lt;br&gt;By the end of this book, you'll have a complete scraping application to use and rewrite to suit your needs. As a bonus, the author shows you options of how to deploy your spiders into the Cloud to leverage your computer from long-running scraping tasks.&lt;/p&gt;
&lt;p style="font-weight: bold"&gt;What You'll Learn&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Install and implement scraping tools individually and together &lt;/li&gt;
&lt;li&gt;Run spiders to crawl websites for data from the cloud &lt;/li&gt;
&lt;li&gt;Work with emulators and drivers to extract data from scripted sites &lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Who This Book Is For&lt;/strong&gt;&lt;br&gt;Readers with some previous Python and software development experience, and an interest in website scraping.&lt;/p&gt;
&lt;h3&gt;From the Back Cover&lt;/h3&gt;
&lt;p&gt;Closely examine website scraping and data processing: the technique of extracting data from websites in a format suitable for further analysis. You'll review which tools to use, and compare their features and efficiency. Focusing on BeautifulSoup4 and Scrapy, this concise, focused book highlights common problems and suggests solutions that readers can implement on their own.&lt;br&gt;&lt;em&gt;Website Scraping with Python&lt;/em&gt; starts by introducing and installing the scraping tools and explaining the features of the full application that readers will build throughout the book. You'll see how to use BeautifulSoup4 and Scrapy individually or together to achieve the desired results. Because many sites use JavaScript, you'll also employ Selenium with a browser emulator to render these sites and make them ready for scraping. &lt;br&gt;By the end of this book, you'll have a complete scraping application to use and rewrite to suit your needs. As a bonus, the author shows you options of how to deploy your spiders into the Cloud to leverage your computer from long-running scraping tasks. &lt;/p&gt;
&lt;h3&gt;About the Author&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Gabor Laszlo Hajba&lt;/strong&gt; is an IT Consultant who specializes in Java and Python, and holds workshops about Java and Java Enterprise Edition. As the CEO of the JaPy Szoftver Kft in Sopron, Hungary he is responsible for designing and developing customer needs in the enterprise software world. He has also held roles as a software developer with EBCONT Enterprise Technologies, and as an Advanced Software Engineer with Zuhlke Group. He considers himself a workaholic, (hard)core and well-grounded developer, functional minded, freak of portable apps and "a champion Javavore who loves pushing code" and loves to develop in Python.&lt;/p&gt;&lt;/div&gt;</dc:description>
        <dc:publisher>Apress</dc:publisher>
        <dc:identifier opf:scheme="ISBN">9781484239254</dc:identifier>
        <dc:identifier opf:scheme="GOODREADS">43066351</dc:identifier>
        <dc:identifier opf:scheme="GOOGLE">_IBuDwAAQBAJ</dc:identifier>
        <dc:identifier opf:scheme="AMAZON">B07G2ZWNQ3</dc:identifier>
        <dc:language>eng</dc:language>
        <dc:subject>Computers</dc:subject>
        <dc:subject>General</dc:subject>
        <dc:subject>Internet</dc:subject>
        <dc:subject>Languages</dc:subject>
        <dc:subject>Programming</dc:subject>
        <dc:subject>Python</dc:subject>
        <dc:subject>Web Programming</dc:subject>
        <meta name="calibre:author_link_map" content="{&quot;Gábor László Hajba&quot;: &quot;&quot;}"/>
        <meta name="calibre:rating" content="8"/>
        <meta name="calibre:timestamp" content="2023-02-03T16:27:10+00:00"/>
        <meta name="calibre:title_sort" content="Website Scraping With Python: Using BeautifulSoup and Scrapy"/>
        <meta name="calibre:user_metadata:#solutions" content="{&quot;table&quot;: &quot;custom_column_1&quot;, &quot;column&quot;: &quot;value&quot;, &quot;datatype&quot;: &quot;text&quot;, &quot;is_multiple&quot;: null, &quot;kind&quot;: &quot;field&quot;, &quot;name&quot;: &quot;Solutions&quot;, &quot;search_terms&quot;: [&quot;#solutions&quot;], &quot;label&quot;: &quot;solutions&quot;, &quot;colnum&quot;: 1, &quot;display&quot;: {&quot;use_decorations&quot;: false, &quot;description&quot;: &quot;&quot;}, &quot;is_custom&quot;: true, &quot;is_category&quot;: true, &quot;link_column&quot;: &quot;value&quot;, &quot;category_sort&quot;: &quot;value&quot;, &quot;is_csp&quot;: false, &quot;is_editable&quot;: true, &quot;rec_index&quot;: 22, &quot;#value#&quot;: null, &quot;#extra#&quot;: null, &quot;is_multiple2&quot;: {}}"/>
    </metadata>
    <guide>
        <reference type="cover" title="Cover" href="cover.jpg"/>
    </guide>
</package>
