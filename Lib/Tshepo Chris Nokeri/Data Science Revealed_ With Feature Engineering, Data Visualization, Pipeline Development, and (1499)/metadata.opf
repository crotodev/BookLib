<?xml version='1.0' encoding='utf-8'?>
<package xmlns="http://www.idpf.org/2007/opf" unique-identifier="uuid_id" version="2.0">
    <metadata xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:opf="http://www.idpf.org/2007/opf">
        <dc:identifier opf:scheme="calibre" id="calibre_id">1499</dc:identifier>
        <dc:identifier opf:scheme="uuid" id="uuid_id">9cbb61a2-c796-4640-8455-84ca814887b0</dc:identifier>
        <dc:title>Data Science Revealed: With Feature Engineering, Data Visualization, Pipeline Development, and Hyperparameter Tuning</dc:title>
        <dc:creator opf:file-as="Nokeri, Tshepo Chris" opf:role="aut">Tshepo Chris Nokeri</dc:creator>
        <dc:contributor opf:file-as="calibre" opf:role="bkp">calibre (6.29.0) [https://calibre-ebook.com]</dc:contributor>
        <dc:date>2021-03-07T05:00:00+00:00</dc:date>
        <dc:description>&lt;div&gt;
&lt;p&gt;Get insight into data science techniques such as data engineering and visualization, statistical modeling, machine learning, and deep learning. This book teaches you how to select variables, optimize hyper parameters, develop pipelines, and train, test, and validate machine and deep learning models. Each chapter includes a set of examples allowing you to understand the concepts, assumptions, and procedures behind each model.&lt;/p&gt;
&lt;p&gt;The book covers parametric methods or linear models that combat under- or over-fitting using techniques such as Lasso and Ridge. It includes complex regression analysis with time series smoothing, decomposition, and forecasting. It takes a fresh look at non-parametric models for binary classification (logistic regression analysis) and ensemble methods such as decision trees, support vector machines, and naive Bayes. It covers the most popular non-parametric method for time-event data (the Kaplan-Meier estimator). It also covers ways of solving classification problems using artificial neural networks such as restricted Boltzmann machines, multi-layer perceptrons, and deep belief networks. The book discusses unsupervised learning clustering techniques such as the K-means method, agglomerative and Dbscan approaches, and dimension reduction techniques such as Feature Importance, Principal Component Analysis, and Linear Discriminant Analysis. And it introduces driverless artificial intelligence using H2O.&lt;/p&gt;
&lt;p&gt;After reading this book, you will be able to develop, test, validate, and optimize statistical machine learning and deep learning models, and engineer, visualize, and interpret sets of data. &lt;/p&gt;
&lt;p style="font-weight: bold"&gt;What You Will Learn&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Design, develop, train, and validate machine learning and deep learning models&lt;/li&gt;
&lt;li&gt;Find optimal hyper parameters for superior model performance &lt;/li&gt;
&lt;li&gt;Improve model performance using techniques such as dimension reduction and regularization &lt;/li&gt;
&lt;li&gt;Extract meaningful insights for decision making using data visualization &lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Who This Book Is For&lt;/strong&gt; &lt;strong&gt;&lt;br&gt;&lt;/strong&gt;Beginning and intermediate level data scientists and machine learning engineers &lt;/p&gt;
&lt;h3&gt;From the Back Cover&lt;/h3&gt;
&lt;p&gt;Get insight into data science techniques such as data engineering and visualization, statistical modeling, machine learning, and deep learning. This book teaches you how to select variables, optimize hyper parameters, develop pipelines, and train, test, and validate machine and deep learning models. Each chapter includes a set of examples allowing you to understand the concepts, assumptions, and procedures behind each model.&lt;/p&gt;
&lt;p&gt;The book covers parametric methods or linear models that combat under- or over-fitting using techniques such as Lasso and Ridge. It includes complex regression analysis with time series smoothing, decomposition, and forecasting. It takes a fresh look at non-parametric models for binary classification (logistic regression analysis) and ensemble methods such as decision trees, support vector machines, and naive Bayes. It covers the most popular non-parametric method for time-event data (the Kaplan-Meier estimator). It also covers ways of solving classification problems using artificial neural networks such as restricted Boltzmann machines, multi-layer perceptrons, and deep belief networks. The book discusses unsupervised learning clustering techniques such as the K-means method, agglomerative and Dbscan approaches, and dimension reduction techniques such as Feature Importance, Principal Component Analysis, and Linear Discriminant Analysis. And it introduces driverless artificial intelligence using H2O.&lt;/p&gt;
&lt;p&gt;After reading this book, you will be able to develop, test, validate, and optimize statistical machine learning and deep learning models, and engineer, visualize, and interpret sets of data.&lt;br&gt;You will:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Design, develop, train, and validate machine learning and deep learning models&lt;/li&gt;
&lt;li&gt;Find optimal hyper parameters for superior model performance &lt;/li&gt;
&lt;li&gt;Improve model performance using techniques such as dimension reduction and regularization &lt;/li&gt;
&lt;li&gt;Extract meaningful insights for decision making using data visualization &lt;/li&gt;&lt;/ul&gt;
&lt;p&gt;--This text refers to the paperback edition.&lt;/p&gt;
&lt;h3&gt;About the Author&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Tsheop Chris Nokeri&lt;/strong&gt; harnesses advanced analytics and artificial intelligence to foster innovation and optimize business performance. He has delivered complex solutions to companies in the mining, petroleum, and manufacturing industries. He completed a bachelorâ€™s degree in information management and graduated with an honors degree in business science at the University of the Witwatersrand on a TATA Prestigious Scholarship and a Wits Postgraduate Merit Award. He also was awarded the Oxford University Press Prize. --This text refers to the paperback edition.&lt;/p&gt;&lt;/div&gt;</dc:description>
        <dc:publisher>Apress</dc:publisher>
        <dc:identifier opf:scheme="BARNESNOBLE">1138470340</dc:identifier>
        <dc:identifier opf:scheme="AMAZON">B08Y7N4549</dc:identifier>
        <dc:identifier opf:scheme="ISBN">9781484268698</dc:identifier>
        <dc:language>eng</dc:language>
        <meta name="calibre:timestamp" content="2023-07-16T14:45:36+00:00"/>
        <meta name="calibre:title_sort" content="Data Science Revealed: With Feature Engineering, Data Visualization, Pipeline Development, and Hyperparameter Tuning"/>
        <meta name="calibre:user_metadata:#solutions" content="{&quot;table&quot;: &quot;custom_column_1&quot;, &quot;column&quot;: &quot;value&quot;, &quot;datatype&quot;: &quot;text&quot;, &quot;is_multiple&quot;: null, &quot;kind&quot;: &quot;field&quot;, &quot;name&quot;: &quot;Solutions&quot;, &quot;search_terms&quot;: [&quot;#solutions&quot;], &quot;label&quot;: &quot;solutions&quot;, &quot;colnum&quot;: 1, &quot;display&quot;: {&quot;description&quot;: &quot;&quot;, &quot;use_decorations&quot;: false}, &quot;is_custom&quot;: true, &quot;is_category&quot;: true, &quot;link_column&quot;: &quot;value&quot;, &quot;category_sort&quot;: &quot;value&quot;, &quot;is_csp&quot;: false, &quot;is_editable&quot;: true, &quot;rec_index&quot;: 22, &quot;#value#&quot;: null, &quot;#extra#&quot;: null, &quot;is_multiple2&quot;: {}}"/>
    </metadata>
    <guide>
        <reference type="cover" title="Cover" href="cover.jpg"/>
    </guide>
</package>
